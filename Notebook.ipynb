{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e03718a",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "The following is the code used in the making of a MANU465 Capstone Project for Group 1. The entirety of the code and the data used throughout this project is available at [this github repository](https://github.com/AlbertoMussali-UBC/MANU465_Team1_Project).\n",
    "## Authors\n",
    "\n",
    "|       Name      | Student ID |\n",
    "|:---------------:|:----------:|\n",
    "|   Anant Goyal   |  46894325  |\n",
    "| Alberto Mussali |  50684182  |\n",
    "|    Musa Habib   |  25899808  |\n",
    "| Sadul Bombuwala |  76343292  |\n",
    "\n",
    "## Overview\n",
    "### Motivation\n",
    "Possibly the most incredible aspect of Machine Learning and Artificial Intelligence is the ability to mimic human-like decision making. Upon learning about how Artificial Neural Networks are constructed and how they work, we were incredibly intrigued by the workings of the neural networks without our brains. We see this project as a means to further study and understand the complexities of our minds. Collecting and analyzing brainwave data is something we have never had the opportunity to do, and we hope that during the course of this project we will gain a valuable understanding of how brainwave data within humans can be used for research in the world of Artificial Intelligence.\n",
    "\n",
    "### Goals and Objective\n",
    "**Objective: To be able to use machine learning models to predict whether or not a person is fatigued, based on brainwave data.**\n",
    "\n",
    "The Muse 2 is a multi-sensor meditation device that provides real-time feedback on brain activity, heart rate, breathing, and body movements to help users build a consistent meditation practice. When paired with the Mind Monitor phone application, one can view and analyze the neural oscillation readings picked up by the Muse 2, and use this headband for purposes beyond mediation.\n",
    "\n",
    "> [https://choosemuse.com/muse-2/](https://choosemuse.com/muse-2/)  \n",
    "> [https://mind-monitor.com/](https://mind-monitor.com/)\n",
    "\n",
    "Our project aims to use these tools to collect data on the variations in brain activity when an individual is in a Sleep-deprived state of mind, and compare this to when they are well rested. Using this data we plan to build a Machine Learning algorithm which accurately predicts the level of sleep deprivation of an individual, based on the brainwave data passed into the algorithm.\n",
    "\n",
    "## Challenges\n",
    "It should be noted that due to the small amount of data compiled, all the trained models are observed to overfit the dataset. This can be remedied in the future by taking more data over the span of a longer timeframe (approximately 1 year) for multiple subjects on both states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b37fc9f",
   "metadata": {},
   "source": [
    "# General Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29f8ce",
   "metadata": {},
   "source": [
    "## Fix Random State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a96ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 55;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbcaba",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdf3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f1298",
   "metadata": {},
   "source": [
    "# Importing the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894ddf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Delta_TP9</th>\n",
       "      <th>Delta_AF7</th>\n",
       "      <th>Delta_AF8</th>\n",
       "      <th>Delta_TP10</th>\n",
       "      <th>Theta_TP9</th>\n",
       "      <th>Theta_AF7</th>\n",
       "      <th>Theta_AF8</th>\n",
       "      <th>Theta_TP10</th>\n",
       "      <th>Alpha_TP9</th>\n",
       "      <th>...</th>\n",
       "      <th>Gyro_X</th>\n",
       "      <th>Gyro_Y</th>\n",
       "      <th>Gyro_Z</th>\n",
       "      <th>HeadBandOn</th>\n",
       "      <th>HSI_TP9</th>\n",
       "      <th>HSI_AF7</th>\n",
       "      <th>HSI_AF8</th>\n",
       "      <th>HSI_TP10</th>\n",
       "      <th>Battery</th>\n",
       "      <th>Elements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-01 17:54:38.045</td>\n",
       "      <td>1.110457</td>\n",
       "      <td>-0.382196</td>\n",
       "      <td>0.082630</td>\n",
       "      <td>0.743808</td>\n",
       "      <td>0.455723</td>\n",
       "      <td>-0.523256</td>\n",
       "      <td>0.086015</td>\n",
       "      <td>0.487615</td>\n",
       "      <td>0.493558</td>\n",
       "      <td>...</td>\n",
       "      <td>4.134674</td>\n",
       "      <td>-5.824432</td>\n",
       "      <td>-1.510315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-01 17:54:39.045</td>\n",
       "      <td>0.904642</td>\n",
       "      <td>-0.382196</td>\n",
       "      <td>0.236881</td>\n",
       "      <td>0.613098</td>\n",
       "      <td>0.313527</td>\n",
       "      <td>-0.523256</td>\n",
       "      <td>0.171247</td>\n",
       "      <td>0.546970</td>\n",
       "      <td>0.538756</td>\n",
       "      <td>...</td>\n",
       "      <td>4.329071</td>\n",
       "      <td>-2.990723</td>\n",
       "      <td>-1.644897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-01 17:54:39.187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/muse/elements/jaw_clench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-01 17:54:40.045</td>\n",
       "      <td>0.652124</td>\n",
       "      <td>-0.382196</td>\n",
       "      <td>0.462323</td>\n",
       "      <td>0.410327</td>\n",
       "      <td>0.293693</td>\n",
       "      <td>-0.523256</td>\n",
       "      <td>0.267178</td>\n",
       "      <td>0.466408</td>\n",
       "      <td>0.343593</td>\n",
       "      <td>...</td>\n",
       "      <td>5.622559</td>\n",
       "      <td>-5.099182</td>\n",
       "      <td>-0.732727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-01 17:54:41.043</td>\n",
       "      <td>0.558608</td>\n",
       "      <td>-0.382196</td>\n",
       "      <td>0.502156</td>\n",
       "      <td>0.877835</td>\n",
       "      <td>0.281408</td>\n",
       "      <td>-0.523256</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.469669</td>\n",
       "      <td>0.381862</td>\n",
       "      <td>...</td>\n",
       "      <td>4.882355</td>\n",
       "      <td>-3.536530</td>\n",
       "      <td>-1.652374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2021-11-01 17:56:57.042</td>\n",
       "      <td>1.011459</td>\n",
       "      <td>-0.382196</td>\n",
       "      <td>0.502156</td>\n",
       "      <td>0.955036</td>\n",
       "      <td>0.456557</td>\n",
       "      <td>-0.523256</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.439388</td>\n",
       "      <td>0.575279</td>\n",
       "      <td>...</td>\n",
       "      <td>5.510406</td>\n",
       "      <td>-7.880554</td>\n",
       "      <td>-2.257996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2021-11-01 17:56:57.111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/muse/elements/blink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2021-11-01 17:56:57.852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/muse/elements/blink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2021-11-01 17:56:58.042</td>\n",
       "      <td>1.011459</td>\n",
       "      <td>-0.382196</td>\n",
       "      <td>0.502156</td>\n",
       "      <td>0.955036</td>\n",
       "      <td>0.456557</td>\n",
       "      <td>-0.523256</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.439388</td>\n",
       "      <td>0.575279</td>\n",
       "      <td>...</td>\n",
       "      <td>4.844971</td>\n",
       "      <td>-6.190796</td>\n",
       "      <td>-2.781372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2021-11-01 17:56:58.222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/muse/elements/blink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TimeStamp  Delta_TP9  Delta_AF7  Delta_AF8  Delta_TP10  \\\n",
       "0    2021-11-01 17:54:38.045   1.110457  -0.382196   0.082630    0.743808   \n",
       "1    2021-11-01 17:54:39.045   0.904642  -0.382196   0.236881    0.613098   \n",
       "2    2021-11-01 17:54:39.187        NaN        NaN        NaN         NaN   \n",
       "3    2021-11-01 17:54:40.045   0.652124  -0.382196   0.462323    0.410327   \n",
       "4    2021-11-01 17:54:41.043   0.558608  -0.382196   0.502156    0.877835   \n",
       "..                       ...        ...        ...        ...         ...   \n",
       "156  2021-11-01 17:56:57.042   1.011459  -0.382196   0.502156    0.955036   \n",
       "157  2021-11-01 17:56:57.111        NaN        NaN        NaN         NaN   \n",
       "158  2021-11-01 17:56:57.852        NaN        NaN        NaN         NaN   \n",
       "159  2021-11-01 17:56:58.042   1.011459  -0.382196   0.502156    0.955036   \n",
       "160  2021-11-01 17:56:58.222        NaN        NaN        NaN         NaN   \n",
       "\n",
       "     Theta_TP9  Theta_AF7  Theta_AF8  Theta_TP10  Alpha_TP9  ...    Gyro_X  \\\n",
       "0     0.455723  -0.523256   0.086015    0.487615   0.493558  ...  4.134674   \n",
       "1     0.313527  -0.523256   0.171247    0.546970   0.538756  ...  4.329071   \n",
       "2          NaN        NaN        NaN         NaN        NaN  ...       NaN   \n",
       "3     0.293693  -0.523256   0.267178    0.466408   0.343593  ...  5.622559   \n",
       "4     0.281408  -0.523256   0.337400    0.469669   0.381862  ...  4.882355   \n",
       "..         ...        ...        ...         ...        ...  ...       ...   \n",
       "156   0.456557  -0.523256   0.337400    0.439388   0.575279  ...  5.510406   \n",
       "157        NaN        NaN        NaN         NaN        NaN  ...       NaN   \n",
       "158        NaN        NaN        NaN         NaN        NaN  ...       NaN   \n",
       "159   0.456557  -0.523256   0.337400    0.439388   0.575279  ...  4.844971   \n",
       "160        NaN        NaN        NaN         NaN        NaN  ...       NaN   \n",
       "\n",
       "       Gyro_Y    Gyro_Z  HeadBandOn  HSI_TP9  HSI_AF7  HSI_AF8  HSI_TP10  \\\n",
       "0   -5.824432 -1.510315         1.0      1.0      2.0      1.0       1.0   \n",
       "1   -2.990723 -1.644897         1.0      1.0      2.0      1.0       1.0   \n",
       "2         NaN       NaN         NaN      NaN      NaN      NaN       NaN   \n",
       "3   -5.099182 -0.732727         1.0      1.0      2.0      1.0       1.0   \n",
       "4   -3.536530 -1.652374         1.0      1.0      2.0      1.0       1.0   \n",
       "..        ...       ...         ...      ...      ...      ...       ...   \n",
       "156 -7.880554 -2.257996         1.0      1.0      4.0      2.0       1.0   \n",
       "157       NaN       NaN         NaN      NaN      NaN      NaN       NaN   \n",
       "158       NaN       NaN         NaN      NaN      NaN      NaN       NaN   \n",
       "159 -6.190796 -2.781372         1.0      1.0      4.0      4.0       1.0   \n",
       "160       NaN       NaN         NaN      NaN      NaN      NaN       NaN   \n",
       "\n",
       "     Battery                   Elements  \n",
       "0       70.0                        NaN  \n",
       "1       70.0                        NaN  \n",
       "2        NaN  /muse/elements/jaw_clench  \n",
       "3       70.0                        NaN  \n",
       "4       70.0                        NaN  \n",
       "..       ...                        ...  \n",
       "156     70.0                        NaN  \n",
       "157      NaN       /muse/elements/blink  \n",
       "158      NaN       /muse/elements/blink  \n",
       "159     70.0                        NaN  \n",
       "160      NaN       /muse/elements/blink  \n",
       "\n",
       "[161 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Get Current Working directory and append the data relative dir\n",
    "cwd = os.getcwd()\n",
    "notTiredDir = cwd + r\"\\Data\\Raw\\NotTired\"\n",
    "tiredDir = cwd + r\"\\Data\\Raw\\Tired\"\n",
    "\n",
    "# Hold file locations\n",
    "filesTired=[];\n",
    "filesNotTired=[];\n",
    "\n",
    "#Populate file location arrays\n",
    "for file in os.listdir(notTiredDir):\n",
    "    if file.endswith('.csv'):\n",
    "        filesNotTired.append(os.path.join(notTiredDir, file))\n",
    "for file in os.listdir(tiredDir):\n",
    "        if file.endswith('.csv'):\n",
    "            filesTired.append(os.path.join(tiredDir, file))\n",
    "            \n",
    "#Test reading files by changing num\n",
    "num=6;\n",
    "sample = pd.read_csv(filesNotTired[num])\n",
    "sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e88fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 31 files were added from the NOT TIRED category\n",
      "> 20 files were added from the TIRED category\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mini-Summary of Block\n",
    "print(f\"> {len(filesNotTired)} files were added from the NOT TIRED category\")\n",
    "print(f\"> {len(filesTired)} files were added from the TIRED category\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319198c",
   "metadata": {},
   "source": [
    "## Available Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c44eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features generated by the Muse 2 headband:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TimeStamp</td>\n",
       "      <td>Delta_TP9</td>\n",
       "      <td>Delta_AF7</td>\n",
       "      <td>Delta_AF8</td>\n",
       "      <td>Delta_TP10</td>\n",
       "      <td>Theta_TP9</td>\n",
       "      <td>Theta_AF7</td>\n",
       "      <td>Theta_AF8</td>\n",
       "      <td>Theta_TP10</td>\n",
       "      <td>Alpha_TP9</td>\n",
       "      <td>...</td>\n",
       "      <td>Gyro_X</td>\n",
       "      <td>Gyro_Y</td>\n",
       "      <td>Gyro_Z</td>\n",
       "      <td>HeadBandOn</td>\n",
       "      <td>HSI_TP9</td>\n",
       "      <td>HSI_AF7</td>\n",
       "      <td>HSI_AF8</td>\n",
       "      <td>HSI_TP10</td>\n",
       "      <td>Battery</td>\n",
       "      <td>Elements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3           4          5   \\\n",
       "0  TimeStamp  Delta_TP9  Delta_AF7  Delta_AF8  Delta_TP10  Theta_TP9   \n",
       "\n",
       "          6          7           8          9   ...      29      30      31  \\\n",
       "0  Theta_AF7  Theta_AF8  Theta_TP10  Alpha_TP9  ...  Gyro_X  Gyro_Y  Gyro_Z   \n",
       "\n",
       "           32       33       34       35        36       37        38  \n",
       "0  HeadBandOn  HSI_TP9  HSI_AF7  HSI_AF8  HSI_TP10  Battery  Elements  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Features generated by the Muse 2 headband:\")\n",
    "\n",
    "pd.DataFrame(sample.columns).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04da614",
   "metadata": {},
   "source": [
    "## Raw Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedab32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 161 entries, 0 to 160\n",
      "Data columns (total 39 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   TimeStamp        161 non-null    object \n",
      " 1   Delta_TP9        141 non-null    float64\n",
      " 2   Delta_AF7        141 non-null    float64\n",
      " 3   Delta_AF8        141 non-null    float64\n",
      " 4   Delta_TP10       141 non-null    float64\n",
      " 5   Theta_TP9        141 non-null    float64\n",
      " 6   Theta_AF7        141 non-null    float64\n",
      " 7   Theta_AF8        141 non-null    float64\n",
      " 8   Theta_TP10       141 non-null    float64\n",
      " 9   Alpha_TP9        141 non-null    float64\n",
      " 10  Alpha_AF7        141 non-null    float64\n",
      " 11  Alpha_AF8        141 non-null    float64\n",
      " 12  Alpha_TP10       141 non-null    float64\n",
      " 13  Beta_TP9         141 non-null    float64\n",
      " 14  Beta_AF7         141 non-null    float64\n",
      " 15  Beta_AF8         141 non-null    float64\n",
      " 16  Beta_TP10        141 non-null    float64\n",
      " 17  Gamma_TP9        141 non-null    float64\n",
      " 18  Gamma_AF7        141 non-null    float64\n",
      " 19  Gamma_AF8        141 non-null    float64\n",
      " 20  Gamma_TP10       141 non-null    float64\n",
      " 21  RAW_TP9          141 non-null    float64\n",
      " 22  RAW_AF7          141 non-null    float64\n",
      " 23  RAW_AF8          141 non-null    float64\n",
      " 24  RAW_TP10         141 non-null    float64\n",
      " 25  AUX_RIGHT        141 non-null    float64\n",
      " 26  Accelerometer_X  141 non-null    float64\n",
      " 27  Accelerometer_Y  141 non-null    float64\n",
      " 28  Accelerometer_Z  141 non-null    float64\n",
      " 29  Gyro_X           141 non-null    float64\n",
      " 30  Gyro_Y           141 non-null    float64\n",
      " 31  Gyro_Z           141 non-null    float64\n",
      " 32  HeadBandOn       141 non-null    float64\n",
      " 33  HSI_TP9          141 non-null    float64\n",
      " 34  HSI_AF7          141 non-null    float64\n",
      " 35  HSI_AF8          141 non-null    float64\n",
      " 36  HSI_TP10         141 non-null    float64\n",
      " 37  Battery          141 non-null    float64\n",
      " 38  Elements         20 non-null     object \n",
      "dtypes: float64(37), object(2)\n",
      "memory usage: 49.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#quick view of data\n",
    "sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d9a69",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b7b6a",
   "metadata": {},
   "source": [
    "Note: Initial preprocessing here was done to tailor the data so it could be passed to Jordan Bird's function 'EEG_feature_extraction' (https://github.com/AlbertoMussali-UBC/MANU465_Team1_Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b98b3a",
   "metadata": {},
   "source": [
    "## Creating the RAW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d63f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Extract rows 21-25 from all files,\n",
    "## these are the only 5 features relevant for use in the EEG_feature_extraction function.\n",
    "\n",
    "rowsTired=[];\n",
    "for f in filesTired:\n",
    "    for r in range(pd.read_csv(f).shape[0]):\n",
    "        rowsTired.append(pd.read_csv(f).iloc[r,[0, 21,22,23,24,25]])\n",
    "\n",
    "rowsNotTired=[];\n",
    "for f in filesNotTired:\n",
    "    for r in range(pd.read_csv(f).shape[0]):\n",
    "        rowsNotTired.append(pd.read_csv(f).iloc[r,[0, 21,22,23,24,25]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to DataFrames:\n",
    "\n",
    "data_NT = pd.DataFrame(rowsNotTired);\n",
    "original_NT = data_NT.copy();\n",
    "data_NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c60fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T = pd.DataFrame(rowsTired);\n",
    "original_T = data_T.copy();\n",
    "data_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d41028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check of DataFrames\n",
    "\n",
    "print(f\"Not Tired Data size is: \\t{data_NT.shape}\", f\"\\nTired Data size is: \\t\\t{data_T.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377569cf",
   "metadata": {},
   "source": [
    "## Remove Empty Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f540827",
   "metadata": {},
   "source": [
    "Remove NaN values associated with blinking and jaw clenching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a68143",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T = data_T.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NT = data_NT.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac447c",
   "metadata": {},
   "source": [
    "## Convert Datetime Column to Timestamps\n",
    "Required for compatibility with EEG_feature_extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b71f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "ind = 0;\n",
    "for time in data_T.iloc[:, 0]:\n",
    "    tmstmp = datetime.strptime(str(time), '%Y-%m-%d %H:%M:%S.%f').timestamp()\n",
    "    data_T.iat[ind, 0] = (tmstmp);\n",
    "    ind=ind+1;\n",
    "    \n",
    "ind = 0;\n",
    "for time in data_NT.iloc[:, 0]:\n",
    "    tmstmp = datetime.strptime(str(time), '%Y-%m-%d %H:%M:%S.%f').timestamp()\n",
    "    data_NT.iat[ind, 0] = (tmstmp);\n",
    "    ind=ind+1;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d0b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check \n",
    "data_NT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1dd38",
   "metadata": {},
   "source": [
    "## Save Data to File\n",
    "\n",
    "**Alternative STARTING POINT once data collection is finalized**\n",
    "\n",
    "Note: this step was done to skip Section 3.1 which would take very long to run each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed543e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "savelocT = cwd + r\"\\Data\\Preprocessed\\Tired.csv\"\n",
    "savelocNT = cwd + r\"\\Data\\Preprocessed\\NotTired.csv\"\n",
    "\n",
    "if os.path.exists(savelocT):\n",
    "    os.remove(savelocT)\n",
    "    \n",
    "if os.path.exists(savelocNT):\n",
    "    os.remove(savelocNT)\n",
    "\n",
    "data_T.to_csv(savelocT,  mode='w', index = False)\n",
    "data_NT.to_csv(savelocNT,mode='w', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299045ce",
   "metadata": {},
   "source": [
    "## EEG Feature Generation\n",
    "Execution of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eegFG import EEG_feature_extraction as FG\n",
    "\n",
    "#tried various combinations of Nsamp and Perio\n",
    "#This combination was optimal\n",
    "Nsamp = 50;\n",
    "Perio = 6;\n",
    "\n",
    "xT, yT = FG.generate_feature_vectors_from_samples(file_path=savelocT,\n",
    "                                         nsamples=Nsamp, \n",
    "                                         period=Perio,\n",
    "                                         #state=data_NT.iloc[:,-1],\n",
    "                                         slide_percent=0.05,\n",
    "                                         remove_redundant=False, \n",
    "                                         cols_to_ignore=None)\n",
    "xT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3bc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsamp = 50;\n",
    "Perio = 5;\n",
    "\n",
    "xNT, yNT = FG.generate_feature_vectors_from_samples(file_path=savelocNT,\n",
    "                                         nsamples=Nsamp, \n",
    "                                         period=Perio,\n",
    "                                         #state=data_NT.iloc[:,-1],\n",
    "                                         slide_percent=0.06,\n",
    "                                         remove_redundant=False, \n",
    "                                         cols_to_ignore=None)\n",
    "xNT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a146639",
   "metadata": {},
   "source": [
    "> **The following code was used to optimize feature generation in Jordan Bird's method and can be ignored for now**\n",
    "\n",
    "> ```python\n",
    "> \n",
    "> %%time\n",
    "> \n",
    "> from importlib import reload\n",
    "> \n",
    "> flaggity=False\n",
    "> \n",
    "> tmp_results=[]\n",
    "> thresh = 95;\n",
    "> for ns in range(50,256,1):\n",
    ">     if (flaggity==True):\n",
    ">         break;\n",
    ">     for p in range(3,8):\n",
    ">         \n",
    ">         try:\n",
    ">             reload(FG);\n",
    ">             xT, yT = FG.generate_feature_vectors_from_samples(file_path=savelocT,\n",
    ">                                  nsamples=ns, \n",
    ">                                  period=p,\n",
    ">                                  #state=data_NT.iloc[:,-1],\n",
    ">                                  slide_percent=0.01,\n",
    ">                                  remove_redundant=False, \n",
    ">                                  cols_to_ignore=None)\n",
    ">             \n",
    ">             xNT, yNT = FG.generate_feature_vectors_from_samples(file_path=savelocNT,\n",
    ">                                  nsamples=ns, \n",
    ">                                  period=p,\n",
    ">                                  #state=data_NT.iloc[:,-1],\n",
    ">                                  slide_percent=0.01,\n",
    ">                                  remove_redundant=False, \n",
    ">                                  cols_to_ignore=None)\n",
    ">         \n",
    ">         except (UnboundLocalError):\n",
    ">             continue;\n",
    ">             \n",
    ">         \n",
    ">         if (xNT.shape[1] == xT.shape[1]):\n",
    ">             print('Cols match!', xT.shape, xNT.shape)\n",
    ">             if (xNT.shape[0] >= thresh and xT.shape[0] >= thresh):\n",
    ">                 print('Thresh met.')\n",
    ">                 tmp_results.append((ns,p,xNT.shape[0],xT.shape[0],xNT.shape[1]))\n",
    ">                 flaggity=True;\n",
    ">                 break;\n",
    ">                 \n",
    ">                 \n",
    "> tmp_results\n",
    "> \n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186df3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#some quick checks\n",
    "\n",
    "X_NT = pd.DataFrame(np.real(xNT))\n",
    "X_NT.columns = np.hstack((['TimeStamp'], yNT))\n",
    "X_NT.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511f0e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(pd.DataFrame(pd.DataFrame(X_NT).head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T = pd.DataFrame(np.real(xT))\n",
    "X_T.columns = np.hstack((['TimeStamp'], yT))\n",
    "X_T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop TimeStamps as they are not needed anymore\n",
    "\n",
    "X_T=X_T.iloc[:,1:];\n",
    "X_NT=X_NT.iloc[:,1:];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca164775",
   "metadata": {},
   "source": [
    "## Attach Labels for Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a789c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack ones or zeros for each class [0 = NotTired, 1 = Tired]\n",
    "X_T = pd.DataFrame(np.hstack((X_T.to_numpy(),   np.ones((X_T.shape[0], 1)))))\n",
    "X_NT= pd.DataFrame(np.hstack((X_NT.to_numpy(), np.zeros((X_NT.shape[0], 1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba797ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add label heading\n",
    "X_T.columns  = np.hstack((yT, ['Target']))\n",
    "X_NT.columns = np.hstack((yNT, ['Target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1a680",
   "metadata": {},
   "source": [
    "## Check Column Coherency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf61b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure Data is Coherent (same number of columns for X_T and X_NT)\n",
    "\n",
    "print(X_T.shape[1], X_NT.shape[1])\n",
    "\n",
    "if (X_T.shape[1] == X_NT.shape[1]):\n",
    "    dataset = np.vstack((X_T, X_NT))\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    print('Columns are coherent')\n",
    "else:\n",
    "    print('NOT COHERENT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde692d5",
   "metadata": {},
   "source": [
    "## Randomize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b64f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = np.hstack((yT, ['Target']))\n",
    "dataset = dataset.sample(frac = 1).reset_index(drop=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3028e",
   "metadata": {},
   "source": [
    "## Separating Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "#Y labeled for plotting or result check\n",
    "def label(n):\n",
    "    if (n==0):\n",
    "        return 'Not Tired'\n",
    "    return 'Tired'\n",
    "\n",
    "y_labeled = list(map(label, y));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376b6f3",
   "metadata": {},
   "source": [
    "## Splitting Dataset into the Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220d593",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Note for future: see if this step is not needed as we rescale the PCs anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eed627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scX = StandardScaler();\n",
    "scX.fit(X_train); #Fit to training data only\n",
    "x = scX.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick view of scaled data\n",
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c0ce8",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "## Calculate Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03832385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "information = 225; #15^2=225;\n",
    "PrinCom=PCA(n_components=information, random_state = SEED)\n",
    "PrinCom.fit(X_train)\n",
    "\n",
    "#save as new variable for PCs so as to not tamper with old variable\n",
    "Z_train = PrinCom.transform(X_train);\n",
    "Z_test  = PrinCom.transform(X_test);\n",
    "Z       = PrinCom.transform(x)\n",
    "\n",
    "print('Train set shape = ',Z_train.shape, '\\nTest set shape  = ',Z_test.shape)\n",
    "\n",
    "\n",
    "pd.DataFrame(Z).describe() #Data No longer Standard\n",
    "print(f\"Using the first {Z.shape[1]} Principal Components describes {np.round(PrinCom.explained_variance_ratio_.sum() * 100,5)}% of the data.\")\n",
    "pd.DataFrame(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded99964",
   "metadata": {},
   "source": [
    "## Scaling the Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d9d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Ignore for now - Ask Ahmad later [Al&Mus]\n",
    "# scZ = StandardScaler();\n",
    "# scZ.fit(Z_train);\n",
    "# Z = scZ.transform(Z)\n",
    "# Z_train = scZ.transform(Z_train)\n",
    "# Z_test = scZ.transform(Z_test)\n",
    "# pd.DataFrame(Z).head()\n",
    "\n",
    "scZ = StandardScaler();\n",
    "scZ.fit(Z);\n",
    "Z = scZ.transform(Z)\n",
    "pd.DataFrame(Z).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c454b4",
   "metadata": {},
   "source": [
    "# Image Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef459bac",
   "metadata": {},
   "source": [
    "## Rescaling and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034aebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale all the PCA components on 0-256 (image greyscale range)\n",
    "\n",
    "\n",
    "def gen_images(data):\n",
    "    images=[];\n",
    "    for r in range(0,data.shape[0]): #Cycle over rows\n",
    "        pixels=[];\n",
    "        mini=min(data[r,:])\n",
    "        maxi=max(data[r,:])\n",
    "        m = (maxi-mini)/(256);\n",
    "\n",
    "        for c in range(0,225): #Cycle over cols\n",
    "            curPixel = data[r,c]\n",
    "            pixels.append((((curPixel - mini) / (maxi - mini)) * 255.9).astype(np.uint8))\n",
    "\n",
    "        #once cols are done running add the image to the images[] array\n",
    "        img = np.reshape(pixels, (15,15)); #reshape into a square image\n",
    "        images.append(img)\n",
    "        \n",
    "    return images;\n",
    "   \n",
    "#Generate images from each data split \n",
    "all_images  = gen_images(Z)\n",
    "x_train_img = gen_images(Z_train)\n",
    "x_test_img  = gen_images(Z_test)\n",
    "\n",
    "#Get number of rows in each data split\n",
    "height_total = Z.shape[0];\n",
    "height_train = Z_train.shape[0];\n",
    "height_test =  Z_test.shape[0];\n",
    "\n",
    "#Reshape into input shape for CNN models\n",
    "#15,15,1 indicates a 15x15 pixel greyscale image\n",
    "x_train_img = np.array(x_train_img).reshape(height_train,15,15,1)\n",
    "x_test_img  = np.array(x_test_img).reshape(height_test,15,15,1)\n",
    "all_images  = np.array(all_images).reshape(height_total,15,15,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037ce50",
   "metadata": {},
   "source": [
    "## Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "# Relative paths to saved folders\n",
    "TiredImgFolder = cwd + r\"\\Data\\GeneratedImages\\Tired\"\n",
    "NotTiredImgFolder = cwd + r\"\\Data\\GeneratedImages\\Not Tired\"\n",
    "\n",
    "# Clear the folders\n",
    "import glob\n",
    "\n",
    "files = glob.glob(TiredImgFolder + r\"\\*\")\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(NotTiredImgFolder + r\"\\*\")\n",
    "for f in files:\n",
    "    os.remove(f)   \n",
    "\n",
    "\n",
    "ctr1=0;\n",
    "ctr2=0;\n",
    "for img in all_images.reshape(height_total,15,15):\n",
    "    \n",
    "    if (y[ctr1+ctr2] == 0): #Not Tired\n",
    "        fstr = NotTiredImgFolder + r\"\\img_\" + str(ctr1) + r\".png\"\n",
    "        imageio.imwrite(fstr, img[:, :], dpi=(300,300))\n",
    "        ctr1+=1; #Counter\n",
    "    else:\n",
    "        fstr = TiredImgFolder + r\"\\img_\" + str(ctr2) + r\".png\"\n",
    "        imageio.imwrite(fstr, img[:, :], dpi=(300,300))\n",
    "        ctr2+=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c3c13c",
   "metadata": {},
   "source": [
    "## Image Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64d02f",
   "metadata": {},
   "source": [
    "### Datagen Definitions\n",
    "Generate image data for each of the images - allows us to generate more images to increase input to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a714341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#rpath to IMageFolder\n",
    "genimgsPath = cwd + r\"\\Data\\GeneratedImages\"\n",
    "\n",
    "r  = 1       #rescale\n",
    "sr = 0.2     #shear range\n",
    "zr = 0.2     #zoom range\n",
    "hf = False   #horizontal flip\n",
    "\n",
    "ValidationSplit = 0.2\n",
    "\n",
    "imageGenerator = ImageDataGenerator(rescale = r,\n",
    "                                   shear_range = sr,\n",
    "                                   zoom_range = zr,\n",
    "                                   horizontal_flip = hf,\n",
    "                                   validation_split=ValidationSplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44bebf",
   "metadata": {},
   "source": [
    "### Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = imageGenerator.flow_from_directory(genimgsPath,\n",
    "                                                target_size = (15, 15),\n",
    "                                                batch_size = 32,\n",
    "                                                subset=\"training\",        #creates training subset\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True,\n",
    "                                                color_mode=\"grayscale\")\n",
    "\n",
    "imgs_test = imageGenerator.flow_from_directory(genimgsPath,\n",
    "                                               target_size = (15, 15),\n",
    "                                               batch_size = 32,\n",
    "                                               subset=\"validation\",       #creates test subset\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               color_mode=\"grayscale\")\n",
    "print(imgs_test.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed942a75",
   "metadata": {},
   "source": [
    "## Image Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change n to see a different data image\n",
    "n = 10\n",
    "sns.heatmap(all_images.reshape(height_total,15,15)[n], cmap='gray');\n",
    "print(f'This image is for the: \\\"{y_labeled[n]}\\\" class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nth row of data\n",
    "n=252\n",
    "sns.heatmap(all_images.reshape(height_total,15,15)[n], cmap='gray');\n",
    "print(f'This image is for the: \\\"{y_labeled[n]}\\\" class.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ca238",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb11e2",
   "metadata": {},
   "source": [
    "## General Correlation Matrix for Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = pd.DataFrame(Z).corr(method='pearson');\n",
    "#mask = np.triu(np.ones_like(corr_mat, dtype=bool));\n",
    "plt.figure(dpi=300);\n",
    "plt.subplots(figsize=(21,21));\n",
    "plt.title(\"Pearson's R Correlation Matrix for the top 225 Principal Components\", fontsize=20);\n",
    "sns.heatmap(corr_mat, annot=False, lw=0, linecolor='white', cmap='inferno');\n",
    "#print('Too many features to visualize at once!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = pd.DataFrame(Z[:,0:25]).corr(method='pearson');\n",
    "mask = np.triu(np.ones_like(corr_mat, dtype=bool));\n",
    "plt.figure(dpi=300);\n",
    "plt.subplots(figsize=(10,8));\n",
    "plt.title(\"Pearson's R Correlation Matrix for the top 25 Principal Components\", fontsize=12);\n",
    "sns.heatmap(corr_mat, annot=False, lw=0.2, linecolor='white', cmap='inferno', mask=mask);\n",
    "#print('Too many features to visualize at once!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2066cd8",
   "metadata": {},
   "source": [
    "## Plotting the Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f28af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=4;\n",
    "p2=100;\n",
    "ax1 = sns.scatterplot(x=Z[:,p1], y=Z[:,p2], hue=y_labeled);\n",
    "ax1.set(title='Principal Components',\n",
    "        ylabel=f'Principal Component {p2}',\n",
    "        xlabel=f'Principal Component {p1}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcf2c3",
   "metadata": {},
   "source": [
    "## PC Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc127e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_title=[];\n",
    "for i in range(1,25):\n",
    "    pc_title.append(f'Principal Component {i}');\n",
    "\n",
    "Z25 = Z[:,0:25]  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "with warnings.catch_warnings():      #Catch warnings in code section\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    plt.subplots(figsize=(10,10));\n",
    "    ax = plt.gca();\n",
    "    pd.DataFrame(Z25).hist(bins=30, figsize=(1,1), grid=False, layout=(5,5), sharex=False, ax=ax, alpha=0.5);\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af5e6c",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d827c1",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e40479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f891f53",
   "metadata": {},
   "source": [
    "## Basic ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de643f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array to hold model info (str: name, model: model, data_to_take: z/img)\n",
    "models = []; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basicANN(optimizer='adam', epochs=100, batch_size=50, neurons=225):\n",
    "    \n",
    "    #Initializing ANN\n",
    "    m= tf.keras.models.Sequential()\n",
    "    \n",
    "    #Add input layer\n",
    "    m.add(tf.keras.layers.Dense(units=neurons, activation='relu'))\n",
    "    \n",
    "    #Add hidden layer\n",
    "    m.add(tf.keras.layers.Dense(units=(neurons/2), activation='relu'))\n",
    "    \n",
    "    #Add output layer\n",
    "    m.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    #Compiling ANN\n",
    "    m.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #Return compiled, unfitted model\n",
    "    return m;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91288d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Build Model, Using defaults\n",
    "## mANNBasic = build_basicANN() \n",
    "mANNBasic = (KerasClassifier(build_fn=build_basicANN, epochs=100, batch_size=50, optimizer='adam', verbose=0));\n",
    "\n",
    "#Training ANN\n",
    "hist_ANNBasic = mANNBasic.fit(Z_train, y_train, batch_size = 100, epochs = 100, verbose=0)\n",
    "\n",
    "models.append(('ANN Basic', mANNBasic, 'z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f8a3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Accuracy of the unoptimized Basic ANN model = {round(accuracy_score(y_true=y_test, y_pred=mANNBasic.predict(x=Z_test)) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddad23",
   "metadata": {},
   "source": [
    "## Basic CNN Model\n",
    "See report for info on how we defined \"Basic\" vs \"Advanced\" CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d04c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random-ish architecture\n",
    "\n",
    "def build_basicCNN(optimizer='adam', epochs=100, batch_size=50, neurons=225):\n",
    "    \n",
    "    m = tf.keras.models.Sequential()\n",
    "    m.add(tf.keras.layers.Conv2D(filters=neurons, kernel_size=3, activation='relu', input_shape=[15, 15, 1]))\n",
    "    m.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    m.add(tf.keras.layers.Conv2D(filters=neurons/2, kernel_size=3, activation='relu'))\n",
    "    m.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    m.add(tf.keras.layers.Flatten())\n",
    "    m.add(tf.keras.layers.Dense(units=neurons, activation='relu'))\n",
    "    m.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    m.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return m;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bddb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Build model using defaults\n",
    "#mCNNBasic = build_basicCNN()\n",
    "mCNNBasic = (KerasClassifier(build_fn=build_basicCNN, epochs=100, batch_size=50, optimizer='adam', verbose=0));\n",
    "\n",
    "### ORIGINAL\n",
    "hist_CNNBasic = mCNNBasic.fit(x=x_train_img,\n",
    "                              y=y_train, \n",
    "                              batch_size = 50,\n",
    "                              epochs = 100, \n",
    "                              verbose=0,\n",
    "                              callbacks=es,\n",
    "                              validation_data=(x_test_img, y_test))\n",
    "\n",
    "\n",
    "models.append(('CNN Basic', mCNNBasic, 'img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931752d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy of the unoptimized Basic CNN model = {round(accuracy_score(y_true=y_test, y_pred=mCNNBasic.predict(x=x_test_img)) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### DATAGEN -- DOES NOT USE KERASCLASSIFIER DUE TO ERROR\n",
    "mCNNBasic2 = build_basicCNN()\n",
    "hist_CNNBasic2 = mCNNBasic2.fit(\n",
    "                               x=imgs_train,\n",
    "                               #y=y_train, \n",
    "                               batch_size = 50,\n",
    "                               epochs = 100, \n",
    "                               verbose=0,\n",
    "                               callbacks=es,\n",
    "                               validation_data=imgs_test\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04615d",
   "metadata": {},
   "source": [
    "## Advanced CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_advancedCNN(optimizer='adam', epochs=100, batch_size=50, neurons=225):\n",
    "    #params\n",
    "    initFilt = neurons;\n",
    "    initUnits= neurons;\n",
    "    \n",
    "    #model\n",
    "    m = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=initFilt, kernel_size=3, activation='relu', input_shape=[15,15,1]),\n",
    "        tf.keras.layers.Conv2D(filters=initFilt/2, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=initUnits),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    m.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return m;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# build using defaults\n",
    "#mCNNAdvanced = build_advancedCNN()\n",
    "mCNNAdvanced = (KerasClassifier(build_fn=build_advancedCNN, epochs=100, batch_size=50, optimizer='adam', verbose=0));\n",
    "\n",
    "#fit\n",
    "hist_CNNAdvanced = mCNNAdvanced.fit(x_train_img,\n",
    "                      y=y_train, \n",
    "                      batch_size = 50,\n",
    "                      epochs = 100, \n",
    "                      verbose=0,\n",
    "                      callbacks=es,\n",
    "                      validation_data=(x_test_img, y_test))\n",
    "\n",
    "models.append(('CNN Advanced', mCNNAdvanced, 'img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) #ignore warnings\n",
    "\n",
    "print(f'Accuracy of the unoptimized Advanced CNN model = {round(accuracy_score(y_true=y_test, y_pred=mCNNAdvanced.predict(x=x_test_img)) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032bf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### DATAGEN -- DOES NOT USE KERASCLASSIFIER DUE TO ERROR\n",
    "mCNNAdvanced2 = build_advancedCNN()\n",
    "hist_CNNAdvanced2 = mCNNBasic2.fit(\n",
    "                               x=imgs_train,\n",
    "                               #y=y_train, \n",
    "                               batch_size = 50,\n",
    "                               epochs = 100, \n",
    "                               verbose=0,\n",
    "                               callbacks=es,\n",
    "                               validation_data=imgs_test\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086e62f",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFCmodel = RandomForestClassifier(n_estimators=100); #N_estimators and criterion can be optimized.\n",
    "RFCmodel.fit(Z_train, y_train);\n",
    "models.append(('RF', RFCmodel, 'z'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2df228",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ada42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LRmodel = LogisticRegression(solver='newton-cg');\n",
    "LRmodel.fit(Z_train, y_train);\n",
    "models.append(('LR',LRmodel, 'z'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dcef48",
   "metadata": {},
   "source": [
    "# Performance Comparison\n",
    "## Via K-Fold Cross-Validation\n",
    "### For SKLearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Suppress warnings for non-convergent ANN models\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Number of splits to make.\n",
    "N = 3;\n",
    "\n",
    "\n",
    "CV_results = [];\n",
    "scoring = 'accuracy';\n",
    "\n",
    "trun=0;\n",
    "for tp in models:\n",
    "    \n",
    "    #Check whether model uses Z dataset or images for training\n",
    "    mode = tp[2];\n",
    "    \n",
    "    if (mode == 'z'):\n",
    "        kfold = StratifiedKFold(n_splits=N, shuffle=True)\n",
    "        #kfold = model_selection.KFold(n_splits=N);\n",
    "        CVinternal_results = model_selection.cross_val_score(tp[1], Z, y, cv=kfold, scoring=scoring);\n",
    "        CV_results.append((CVinternal_results));\n",
    "        \n",
    "    if (mode == 'img'):\n",
    "        kfold = StratifiedKFold(n_splits=N, shuffle=True)\n",
    "        #kfold = model_selection.KFold(n_splits=N);\n",
    "        CVinternal_results = model_selection.cross_val_score(tp[1], all_images, y, cv=kfold, scoring=scoring);\n",
    "        CV_results.append((CVinternal_results));    \n",
    "    \n",
    "    print(f'run#{trun} for model \\\"{tp[0]}\\\" returned {CVinternal_results}')\n",
    "    trun+=1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aedd1c",
   "metadata": {},
   "source": [
    "### For Keras Models\n",
    "$\\color{red}{NOTE:}$ The Following was not implemented due to model overfitting by all developed ML models. The results of K-Fold CV are essentially useless until more data is compiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [];\n",
    "for tp in models:\n",
    "    names.append(tp[0]);\n",
    "    \n",
    "CVdf = pd.DataFrame(CV_results).T;\n",
    "CVdf.columns = names;\n",
    "CVdf.T\n",
    "\n",
    "ax2 = sns.boxplot(data=CVdf, palette='Spectral')\n",
    "ax2.set(xlabel = \"ML Algorithm\",\n",
    "       ylabel = 'Accuracy',\n",
    "       title = f\"ML Algorithm Accuracy Comparison \\nfor Cross-Validation with {N} Splits\");\n",
    "sns.despine(ax=ax2,offset=5, trim=False)\n",
    "ax2.plot();\n",
    "plt.ylim(0.95,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37cd74",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "With the availability of sophisticated technology such as the Muse 2, it is valuable to understand how brainwave data is impacted by the level of fatigue experienced by a person. Our study aimed to determine whether a machine learning model can accurately predict if a person is fatigued or not simply by analyzing their brainwaves.\n",
    "\n",
    "After collecting data for both fatigued and not fatigued individuals, randomizing and scaling the data and training five different machine learning models on the dataset, our study concluded that all of our models (Artificial Neural Network, two different Convolutional Neural Network, Random Forest and Logistic Regression) were able to predict fatigued or not with an accuracy of 100% or very close to it. Although our results show our study to be surprisingly promising, it is important to note machine learning models tend to overfit smaller amounts of data input resulting in an accuracy of 100%, as is the case in our study. Due to this reason, it is difficult to compare the accuracy of one model to another. \n",
    "\n",
    "Future research into the correlation between brain activity and state of fatigue should aim to apply data collected over the span of many months. Furthermore, while our research focused on fatigue resulting from sleep deprivation, this can be expanded to include a wide range of both physical and mental fatigue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
